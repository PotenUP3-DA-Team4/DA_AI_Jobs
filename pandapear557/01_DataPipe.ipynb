{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\PotenUP_AI\\PJ02-DATA-ANALYSIS_Team4\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\user\\.cache\\kagglehub\\datasets\\terencekatua\\global-ai-job-market-dataset-20102025\\versions\\1\n",
      "Path to dataset files: C:\\Users\\user\\.cache\\kagglehub\\datasets\\ankit0017\\ai-and-ml-job-postings-linkedin-and-indeed-2025\\versions\\1\n",
      "Path to dataset files: C:\\Users\\user\\.cache\\kagglehub\\datasets\\arshkon\\linkedin-job-postings\\versions\\13\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# # Global AI Job Market Dataset (2010–2025)\n",
    "# path = kagglehub.dataset_download(\"terencekatua/global-ai-job-market-dataset-20102025\")\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# # AI & ML Job_Postings LinkedIn & Indeed (2025)\n",
    "# path = kagglehub.dataset_download(\"ankit0017/ai-and-ml-job-postings-linkedin-and-indeed-2025\")\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# #LinkedIn Job Postings (2023 - 2024)\n",
    "# path = kagglehub.dataset_download(\"arshkon/linkedin-job-postings\")\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3261f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "import src.utils as src\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968fb172",
   "metadata": {},
   "source": [
    "# 데이터 명세\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a37008",
   "metadata": {},
   "source": [
    "### **01. Global AI Job Market Dataset (2010–2025)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1354937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/global-ai-job-market_10-25/ai_impact_jobs_2010_2025.csv\")\n",
    "\n",
    "# 데이터셋의 형태 확인\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2c9161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 22 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   job_id                              5000 non-null   str    \n",
      " 1   posting_year                        5000 non-null   int64  \n",
      " 2   country                             5000 non-null   str    \n",
      " 3   region                              5000 non-null   str    \n",
      " 4   city                                5000 non-null   str    \n",
      " 5   company_name                        5000 non-null   str    \n",
      " 6   company_size                        5000 non-null   str    \n",
      " 7   industry                            5000 non-null   str    \n",
      " 8   job_title                           5000 non-null   str    \n",
      " 9   seniority_level                     5000 non-null   str    \n",
      " 10  ai_mentioned                        5000 non-null   bool   \n",
      " 11  ai_keywords                         1623 non-null   str    \n",
      " 12  ai_intensity_score                  5000 non-null   float64\n",
      " 13  core_skills                         5000 non-null   str    \n",
      " 14  ai_skills                           1623 non-null   str    \n",
      " 15  salary_usd                          5000 non-null   int64  \n",
      " 16  salary_change_vs_prev_year_percent  5000 non-null   float64\n",
      " 17  automation_risk_score               5000 non-null   float64\n",
      " 18  reskilling_required                 5000 non-null   bool   \n",
      " 19  ai_job_displacement_risk            5000 non-null   str    \n",
      " 20  job_description_embedding_cluster   5000 non-null   int64  \n",
      " 21  industry_ai_adoption_stage          5000 non-null   str    \n",
      "dtypes: bool(2), float64(3), int64(3), str(14)\n",
      "memory usage: 791.1 KB\n"
     ]
    }
   ],
   "source": [
    "# 데이터 타입 확인 Non-Null count와 dtype을 통해 추론\n",
    "# 핵심적인 numeric 변수는 sararly_usd\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b964cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns (< 20 unique values): 10\n",
      "Numerical columns (>= 20 unique values): 10\n",
      "Neither categorical or numerical {'ai_mentioned', 'reskilling_required'}\n"
     ]
    }
   ],
   "source": [
    "# int와 float 타입의 column만 선택\n",
    "numeric_cols = df.select_dtypes(include=['int', 'float', 'str']).columns.tolist()\n",
    "\n",
    "# 유니크 값 개수에 따라 분류\n",
    "cat_columns = []\n",
    "num_columns = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if df[col].nunique() < 20:\n",
    "        cat_columns.append(col)\n",
    "    else:\n",
    "        num_columns.append(col)\n",
    "\n",
    "print(\"Categorical columns (< 20 unique values):\", len(cat_columns))\n",
    "print(\"Numerical columns (>= 20 unique values):\", len(num_columns))\n",
    "print(\"Neither categorical or numerical\", set(df.columns) - set(cat_columns) - set(num_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31be6fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posting_year : 16\n",
      "region : 9\n",
      "city : 14\n",
      "company_name : 16\n",
      "company_size : 5\n",
      "industry : 9\n",
      "job_title : 10\n",
      "seniority_level : 6\n",
      "ai_job_displacement_risk : 3\n",
      "industry_ai_adoption_stage : 3\n",
      "city\n",
      "Bangalore    9\n",
      "Berlin       9\n",
      "Dubai        9\n",
      "Lagos        9\n",
      "London       9\n",
      "Nairobi      9\n",
      "New York     9\n",
      "Paris        9\n",
      "Sao Paulo    9\n",
      "Seoul        9\n",
      "Singapore    9\n",
      "Sydney       9\n",
      "Tokyo        9\n",
      "Toronto      9\n",
      "Name: region, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8     South Asia\n",
       "16        Africa\n",
       "17    South Asia\n",
       "34        Africa\n",
       "36        Europe\n",
       "Name: region, dtype: str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 범주형 변수의 유니크 값 확인 \n",
    "[print(i,':', len(df[i].unique())) for i in cat_columns]\n",
    "\n",
    "# 종속성 확인\n",
    "# city는 region과 개념적 종속성을 가지고 있음\n",
    "# # 근데 여기선 랜덤하게 나옴\n",
    "# 따라서 지역변수는 아무런 정보 가치가 없음\n",
    "\n",
    "print(df.groupby('city')['region'].nunique())\n",
    "\n",
    "# \n",
    "df[df['city'] == 'Bangalore'][\"region\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66cc0e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_id : 5000 str\n",
      "country : 44 str\n",
      "ai_keywords : 618 str\n",
      "ai_intensity_score : 77 float64\n",
      "core_skills : 4162 str\n",
      "ai_skills : 618 str\n",
      "salary_usd : 4883 int64\n",
      "salary_change_vs_prev_year_percent : 1815 float64\n",
      "automation_risk_score : 62 float64\n",
      "job_description_embedding_cluster : 20 int64\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "✅ 'ai_skills'은(는) 'ai_keywords'에 의해 결정됩니다. (1:1 또는 N:1 관계)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수치형 변수의 유니크 값 확인\n",
    "[print(i,':', len(df[i].unique()), df[i].dtype) for i in num_columns]\n",
    "print(\"\\n\")\n",
    "print(\"----\"*20)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 개념적인 범주형 변수가 존재함\n",
    "cleaning_li = ['country', \"ai_keywords\", \"core_skills\",\"job_description_embedding_cluster\"]\n",
    "df.loc[df['ai_skills'].notna()][['job_title','ai_skills','core_skills', \"ai_keywords\"]].head()\n",
    "\n",
    "# ai_skills와 _keywords는 거의 동일한 column >> 둘 중 하나는 삭제\n",
    "src.check_dependency(df, \"ai_skills\", \"ai_keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5facc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split skill\n",
    "\n",
    "\n",
    "# 컬럼 정리\n",
    "df[\"year\"] = df[\"posting_year\"].astype(int)\n",
    "df[\"ai_mentioned\"] = df[\"ai_mentioned\"].astype(int)  # 0/1 가정\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) core_skills split/explode + 연도별 카운트\n",
    "# =========================\n",
    "df[\"core_skills\"] = df[\"core_skills\"].fillna(\"\")\n",
    "\n",
    "skills = (\n",
    "    df.assign(core_skill=df[\"core_skills\"].str.split(\",\"))\n",
    "      .explode(\"core_skill\")\n",
    ")\n",
    "\n",
    "skills[\"core_skill\"] = skills[\"core_skill\"].astype(str).str.strip()\n",
    "skills = skills[skills[\"core_skill\"] != \"\"]  # 빈 값 제거\n",
    "\n",
    "skill_counts = (\n",
    "    skills.groupby([\"year\", \"core_skill\"])\n",
    "          .size()\n",
    "          .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# 전체에서 많이 등장한 Top-N 스킬만 추적 (라인 차트 가독성)\n",
    "TOP_N = 10\n",
    "top_skills = (\n",
    "    skill_counts.groupby(\"core_skill\")[\"count\"]\n",
    "               .sum()\n",
    "               .sort_values(ascending=False)\n",
    "               .head(TOP_N)\n",
    "               .index\n",
    "               .tolist()\n",
    ")\n",
    "\n",
    "skill_counts_top = skill_counts[skill_counts[\"core_skill\"].isin(top_skills)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) (추천) 스킬 변화는 '연도별 샘플 수' 영향을 받으니,\n",
    "#    비율(share)로도 같이 보기\n",
    "# =========================\n",
    "# 연도별 총 스킬 토큰 수\n",
    "total_skill_tokens_by_year = (\n",
    "    skill_counts.groupby(\"year\")[\"count\"].sum().reset_index(name=\"total_tokens\")\n",
    ")\n",
    "\n",
    "skill_share = skill_counts.merge(total_skill_tokens_by_year, on=\"year\", how=\"left\")\n",
    "skill_share[\"share\"] = skill_share[\"count\"] / skill_share[\"total_tokens\"]\n",
    "\n",
    "skill_share_top = skill_share[skill_share[\"core_skill\"].isin(top_skills)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adbb2fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.Series"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skills[\"core_skill\"]\n",
    "\n",
    "df[\"core_skills\"].unique()\n",
    "#skill_counts\n",
    "\n",
    "df[df[\"core_skills\"] =='Research, Project Management, Business Analysis']\n",
    "\n",
    "type(skills[\"core_skill\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436dca9",
   "metadata": {},
   "source": [
    "### **02. AI & ML Job_Postings LinkedIn & Indeed (2025)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e09ffb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AI & ML Job Postings Dataset — LinkedIn & Indeed (2025)\n",
      "\n",
      "This dataset contains **time-stamped AI & ML job postings** scraped from **LinkedIn** and **Indeed** over multiple days, covering companies, roles, and locations. It includes:\n",
      "\n",
      "- `link`: URL to the job posting\n",
      "- `title`: Job title (e.g., Data Scientist, ML Engineer)\n",
      "- `company`: Company name\n",
      "- `location`: City, state, or country\n",
      "- `date` & `time`: Job posting timestamp\n",
      "- `scrape_date` & `scrape_time`: When the data was collected\n",
      "\n",
      "**Dataset Highlights:**\n",
      "- ~1,550 unique postings, clean and deduplicated\n",
      "- Ready for **EDA, visualization, and ML experiments**\n",
      "- Includes **scrape metadata** for temporal analysis\n",
      "\n",
      "**Potential Use Cases:**\n",
      "- Trend analysis of AI/ML hiring over time\n",
      "- Skill extraction and NLP on job titles\n",
      "- Job classification or predictive modeling projects\n",
      "- Company hiring insights and labor market research\n",
      "- Geospatial analysis of AI/ML demand\n",
      "\n",
      "**Included Notebook:** `EDA_Job_Postings.ipynb`  \n",
      "- Exploratory data analysis with top companies, job titles, locations, and word clouds\n",
      "- Time-series analysis of job postings\n",
      "\n",
      "**License:** CC BY 4.0 — free for research, educational, and analysis purposes with attribution.\n",
      "\n",
      "**Note:** Data was collected via public job postings; no personal candidate information is included. Users can further enrich the dataset using the job links if legally permissible.\n",
      "\n",
      "파일명: archive.zip, 형식: application/zip\n",
      "파일명: image/png files, 형식: image/png\n",
      "파일명: jobs_main.csv, 형식: text/csv\n",
      "파일명: merged_jobs.csv, 형식: text/csv\n"
     ]
    }
   ],
   "source": [
    "# metadata\n",
    "import json\n",
    "\n",
    "with open('../data/raw/JobPosting_25(AIML)/ai-and-ml-job-postings-linkedin-and-indeed-2025-metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# 데이터셋 설명 출력\n",
    "print(metadata['description'])\n",
    "\n",
    "# 포함된 파일 목록 확인\n",
    "for dist in metadata['distribution']:\n",
    "    print(f\"파일명: {dist.get('name')}, 형식: {dist.get('encodingFormat')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e9a1a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(682, 6)\n",
      "(1550, 8)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../data/JobPosting_25(AIML)/jobs_main.csv\")\n",
    "df2_merged_job = pd.read_csv(\"../data/JobPosting_25(AIML)/merged_jobs.csv\")\n",
    "\n",
    "# 데이터셋의 형태 확인\n",
    "print(df2.shape)\n",
    "print(df2_merged_job.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c95a5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 682 entries, 0 to 681\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   job_url      682 non-null    str  \n",
      " 1   title        682 non-null    str  \n",
      " 2   company      682 non-null    str  \n",
      " 3   location     487 non-null    str  \n",
      " 4   scrape_date  682 non-null    str  \n",
      " 5   scrape_time  682 non-null    str  \n",
      "dtypes: str(6)\n",
      "memory usage: 32.1 KB\n",
      "None\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1550 entries, 0 to 1549\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   link         1550 non-null   str  \n",
      " 1   title        1550 non-null   str  \n",
      " 2   company      1549 non-null   str  \n",
      " 3   location     1311 non-null   str  \n",
      " 4   date         1550 non-null   str  \n",
      " 5   time         1550 non-null   str  \n",
      " 6   scrape_date  1550 non-null   str  \n",
      " 7   scrape_time  1550 non-null   str  \n",
      "dtypes: str(8)\n",
      "memory usage: 97.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터 타입 확인 Non-Null count와 dtype을 통해 추론\n",
    "# 핵심적인 numeric 변수는 sararly_usd\n",
    "\n",
    "print(df2.info())\n",
    "print(df2_merged_job.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5439f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StringArray>\n",
      "['2025-09-18', '2025-09-19', '2025-09-20', '2025-09-21', '2025-09-22',\n",
      " '2025-09-23', '2025-09-24', '2025-09-25', '2025-09-26', '2025-09-27',\n",
      " '2025-09-28', '2025-09-29', '2025-09-30', '2025-10-01', '2025-10-02',\n",
      " '2025-10-03', '2025-10-04', '2025-10-05', '2025-10-06']\n",
      "Length: 19, dtype: str\n",
      "<StringArray>\n",
      "['2025-09-18', '2025-09-19', '2025-09-20', '2025-09-21', '2025-09-22',\n",
      " '2025-09-23', '2025-09-24', '2025-09-25', '2025-09-26', '2025-09-27',\n",
      " '2025-09-28', '2025-09-29', '2025-09-30', '2025-10-01', '2025-10-02',\n",
      " '2025-10-03', '2025-10-04', '2025-10-05', '2025-10-06']\n",
      "Length: 19, dtype: str\n",
      "<StringArray>\n",
      "['16:44:51', '17:18:02', '18:30:15', '18:50:50', '01:38:14', '03:47:59',\n",
      " '05:18:55', '05:40:14', '06:30:33', '07:19:31',\n",
      " ...\n",
      " '01:38:46', '04:24:27', '04:42:30', '05:19:58', '05:40:25', '06:32:03',\n",
      " '07:20:51', '08:48:24', '09:24:43', '10:23:15']\n",
      "Length: 426, dtype: str\n",
      "<StringArray>\n",
      "['16:44:51', '17:18:02', '18:30:15', '18:50:50', '01:38:14', '03:47:59',\n",
      " '05:18:55', '05:40:14', '06:30:33', '07:19:31',\n",
      " ...\n",
      " '01:38:46', '04:24:27', '04:42:30', '05:19:58', '05:40:25', '06:32:03',\n",
      " '07:20:51', '08:48:24', '09:24:43', '10:23:15']\n",
      "Length: 426, dtype: str\n",
      "✅ 'scrape_date'은(는) 'date'에 의해 결정됩니다. (1:1 또는 N:1 관계)\n",
      "✅ 'scrape_time'은(는) 'time'에 의해 결정됩니다. (1:1 또는 N:1 관계)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df2_merged_job['scrape_date'].unique())\n",
    "print(df2_merged_job['date'].unique())\n",
    "\n",
    "print(df2_merged_job['scrape_time'].unique())\n",
    "print(df2_merged_job['time'].unique())\n",
    "\n",
    "# check Dependency == True\n",
    "src.check_dependency(df2_merged_job, 'scrape_date', 'date')\n",
    "src.check_dependency(df2_merged_job, 'scrape_time', 'time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91f0ebda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2232, 8)\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2232 entries, 0 to 2231\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   url          2232 non-null   str  \n",
      " 1   title        2232 non-null   str  \n",
      " 2   company      2231 non-null   str  \n",
      " 3   location     1798 non-null   str  \n",
      " 4   scrape_date  2232 non-null   str  \n",
      " 5   scrape_time  2232 non-null   str  \n",
      " 6   date         1550 non-null   str  \n",
      " 7   time         1550 non-null   str  \n",
      "dtypes: str(8)\n",
      "memory usage: 139.6 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2232, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge 2 dataframes\n",
    "temp = df2.copy()\n",
    "temp2 = df2_merged_job.copy()\n",
    "\n",
    "temp.rename(columns={'job_url': 'url'}, inplace=True)\n",
    "temp2.rename(columns={'link': 'url'}, inplace=True)\n",
    "\n",
    "temp.head()\n",
    "df_merged = pd.concat([temp, temp2], ignore_index=True)\n",
    "print(df_merged.shape)\n",
    "print(df_merged.info())\n",
    "\n",
    "df_merged.drop(['date','time'], axis=1, inplace=True)\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ba07ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save merged dataframe\n",
    "df_merged.to_csv(\"../data/jobs_merged_0129.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5ce98572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read this check point\n",
    "df2 = pd.read_csv(\"../data/df2_0129.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c5cbc20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>scrape_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2231</td>\n",
       "      <td>1798</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2129</td>\n",
       "      <td>758</td>\n",
       "      <td>967</td>\n",
       "      <td>106</td>\n",
       "      <td>26</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4307968830</td>\n",
       "      <td>Remote Python AI Engineer - 17852</td>\n",
       "      <td>Turing</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>13:55:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>149</td>\n",
       "      <td>284</td>\n",
       "      <td>434</td>\n",
       "      <td>298</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "count                                            2232   \n",
       "unique                                           2129   \n",
       "top     https://www.linkedin.com/jobs/view/4307968830   \n",
       "freq                                               10   \n",
       "\n",
       "                                    title company  \\\n",
       "count                                2232    2231   \n",
       "unique                                758     967   \n",
       "top     Remote Python AI Engineer - 17852  Turing   \n",
       "freq                                  149     284   \n",
       "\n",
       "                           location scrape_date scrape_time  \n",
       "count                          1798        2232        2232  \n",
       "unique                          106          26         600  \n",
       "top     Bengaluru, Karnataka, India  2025-07-16    13:55:55  \n",
       "freq                            434         298          31  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()\n",
    "# url unique unmatched\n",
    "# [\"company\"] freq == 284\n",
    "# location??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5fa6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4306697434</td>\n",
       "      <td>머신러닝 엔지니어 / Machine Learning Engineer</td>\n",
       "      <td>Drift Wave</td>\n",
       "      <td>Seoul, South Korea</td>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>06:31:44</td>\n",
       "      <td>South Korea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                url  \\\n",
       "1682  https://www.linkedin.com/jobs/view/4306697434   \n",
       "\n",
       "                                      title     company            location  \\\n",
       "1682  머신러닝 엔지니어 / Machine Learning Engineer  Drift Wave  Seoul, South Korea   \n",
       "\n",
       "     scrape_date scrape_time      country  \n",
       "1682  2025-09-30    06:31:44  South Korea  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['country'] = df2[\"location\"].str.split(',').apply(lambda x: x[-1].strip() if isinstance(x, list) and len(x) > 0 else '')\n",
    "print(df2[df2['country'] == \"South Korea\"])\n",
    "\n",
    "#idx : 1682 가짜 공고 인듯?\n",
    "# 모든 공고가 인도에 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "299b2a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company\n",
       "Turing                                                   154\n",
       "Uplers                                                    32\n",
       "BairesDev                                                 21\n",
       "Perimattic                                                 4\n",
       "Jobgether                                                  3\n",
       "iBovi - Staffing, Consulting and Recruitment Services      2\n",
       "Seventh Contact Hiring Solutions                           2\n",
       "Call For Referral                                          2\n",
       "VGreen Technology Solutions (VGreenTEK)                    1\n",
       "h3 Technologies, LLC                                       1\n",
       "Smart Working                                              1\n",
       "Live Nation Entertainment                                  1\n",
       "HYI.AI                                                     1\n",
       "BotifyNow AI                                               1\n",
       "MARICI Solutions GmbH                                      1\n",
       "Crossing Hurdles                                           1\n",
       "Arrise Solutions (India) Pvt. Ltd.                         1\n",
       "techolution                                                1\n",
       "datavruti                                                  1\n",
       "KPG99 INC                                                  1\n",
       "Trilogy                                                    1\n",
       "Insight Fusion Analytics                                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remote를 포함하는 job의 특성 문해\n",
    "df2[df2['title'].str.contains('remote', case=False, na=False)][\"company\"].value_counts() # (234, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f5304",
   "metadata": {},
   "source": [
    "### **03. LinkedIn Job Postings (2023 - 2024)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94d12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b24be348",
   "metadata": {},
   "source": [
    "# Utils Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44f6a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 분류 완료: 범주형(10), 수치형(9), 제외된 인덱스(1)\n"
     ]
    }
   ],
   "source": [
    "def classify_columns(df, threshold=20):\n",
    "    \"\"\"\n",
    "    데이터프레임의 컬럼을 범주형(cat)과 수치형(num)으로 자동 분류합니다.\n",
    "    ID나 Index 성격의 컬럼은 수치형에서 제외합니다.\n",
    "    \"\"\"\n",
    "    # 1. 대상 컬럼 선택 (수치형 + 문자열)\n",
    "    # str은 pandas에서 보통 'object' 타입이므로 'object'를 포함합니다.\n",
    "    target_cols = df.select_dtypes(include=['int', 'float', 'str', 'object']).columns.tolist()\n",
    "\n",
    "    cat_columns = []\n",
    "    num_columns = []\n",
    "    index_columns = [] # 인덱스성 컬럼을 따로 관리하면 나중에 확인하기 좋습니다.\n",
    "\n",
    "    for col in target_cols:\n",
    "        # A. 인덱스/ID 컬럼 필터링 (이름에 id/index가 있거나, 모든 값이 유니크할 때)\n",
    "        is_index_name = any(ext in col.lower() for ext in ['id', 'index', 'idx', '_no'])\n",
    "        is_high_cardinality = (df[col].nunique() == len(df))\n",
    "        \n",
    "        if is_index_name or is_high_cardinality:\n",
    "            index_columns.append(col)\n",
    "            continue # index 리스트에 넣었으므로 다음 루프로 넘어감\n",
    "\n",
    "        # B. 유니크 값 개수에 따른 분류\n",
    "        if df[col].nunique() < threshold:\n",
    "            cat_columns.append(col)\n",
    "        else:\n",
    "            num_columns.append(col)\n",
    "\n",
    "    print(f\"✅ 분류 완료: 범주형({len(cat_columns)}), 수치형({len(num_columns)}), 제외된 인덱스({len(index_columns)})\")\n",
    "    \n",
    "    return cat_columns, num_columns, index_columns\n",
    "\n",
    "# 사용 예시\n",
    "cat_list, num_list, idx_list = classify_columns(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8487b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 'city' 중 일부가 여러 'region'에 속해 있습니다.\n",
      "--- 위반 사례 (처음 5개) ---\n",
      "city\n",
      "Bangalore    9\n",
      "Berlin       9\n",
      "Dubai        9\n",
      "Lagos        9\n",
      "London       9\n",
      "Name: region, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_dependency(df, child_col, parent_col):\n",
    "    \"\"\"\n",
    "    child_col(예: city)이 parent_col(예: region)에 완전히 종속되는지 확인합니다.\n",
    "    \"\"\"\n",
    "    # child_col 값 하나당 parent_col 값이 몇 종류인지 계산\n",
    "    counts = df.groupby(child_col)[parent_col].nunique()\n",
    "    \n",
    "    # 모든 child_col에 대해 parent_col 종류가 1개뿐인지 확인\n",
    "    is_dependent = (counts <= 1).all()\n",
    "    \n",
    "    if is_dependent:\n",
    "        print(f\"✅ '{child_col}'은(는) '{parent_col}'에 의해 결정됩니다. (1:1 또는 N:1 관계)\")\n",
    "    else:\n",
    "        # 관계가 깨지는 데이터 추출\n",
    "        conflicts = counts[counts > 1]\n",
    "        print(f\"❌ '{child_col}' 중 일부가 여러 '{parent_col}'에 속해 있습니다.\")\n",
    "        print(f\"--- 위반 사례 (처음 5개) ---\\n{conflicts.head()}\")\n",
    "        \n",
    "    return is_dependent\n",
    "\n",
    "# 사용 예시:\n",
    "check_dependency(df, 'city', 'region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b6b4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PJ02-DATA-ANALYSIS_Team4 (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
