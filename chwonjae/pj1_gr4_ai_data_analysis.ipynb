{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "380943ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [과제 1]데이터를 불러오는 것부터 데이터 탐색까지 파이썬으로 진행해야 하는 플로우를 문서로 작성한다.  \n",
    "# 체크리스트\n",
    "# 1. 각 목차에 필요한 함수는?\n",
    "# 2. 각 목차에서 주의해야할 점은 무엇인가? (EX. EncodeDecodeError 등)\n",
    "# 3. 데이터 탐색 - 왜 해야 하는가?\n",
    "# 4. 데이터 탐색 시 필요한 함수는?\n",
    "\n",
    "# [과제 2]텍스트 데이터 분석 방법들과 그 과정을 문서로 작성한다. \n",
    "# 체크리스트\n",
    "# 1. 텍스트 데이터 분석이 힘든 이유?\n",
    "# 2. 텍스트 데이터 분석 방법(과정 중심, 데이터 형태)\n",
    "# 3. 각각 방법마다 필요한 함수는? \n",
    "# 4. 그 함수를 사용하려면 뭘 입력해야 하는가?\n",
    "# 5. 시각화 해석은 어떻게 할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b7e821",
   "metadata": {},
   "source": [
    "# 0. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2def605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 2,
=======
   "execution_count": 3,
>>>>>>> Stashed changes
   "id": "3729f930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af2dba",
   "metadata": {},
   "source": [
    "# 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afc89df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>scrape_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://in.indeed.com/viewjob?jk=8a6bb0507eba5bbf</td>\n",
       "      <td>Data Engineer/ETL Developer</td>\n",
       "      <td>Princeton IT America</td>\n",
       "      <td>KA, IN</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>12:23:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4265959832</td>\n",
       "      <td>2702- Data Engineer</td>\n",
       "      <td>EXL</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>12:23:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4267652354</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>SatSure</td>\n",
       "      <td>Bangalore Urban, Karnataka, India</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>12:23:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4267647369</td>\n",
       "      <td>DevOps/Cloud Engineer</td>\n",
       "      <td>BayOne Solutions</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>12:23:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4265960423</td>\n",
       "      <td>AI Developer – Immediate Joiners Only</td>\n",
       "      <td>Perimattic</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>12:23:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4309720429</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>People Prime Worldwide</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>2025-10-06</td>\n",
       "      <td>10:23:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4309719532</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>People Prime Worldwide</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>2025-10-06</td>\n",
       "      <td>10:23:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4309701623</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>People Prime Worldwide</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>2025-10-06</td>\n",
       "      <td>10:23:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4309703481</td>\n",
       "      <td>Senior AI Developer - Bangalore</td>\n",
       "      <td>SAP</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>2025-10-06</td>\n",
       "      <td>10:23:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4309718555</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>People Prime Worldwide</td>\n",
       "      <td>Hyderabad, Telangana, India</td>\n",
       "      <td>2025-10-06</td>\n",
       "      <td>10:23:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2232 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0     https://in.indeed.com/viewjob?jk=8a6bb0507eba5bbf   \n",
       "1         https://www.linkedin.com/jobs/view/4265959832   \n",
       "2         https://www.linkedin.com/jobs/view/4267652354   \n",
       "3         https://www.linkedin.com/jobs/view/4267647369   \n",
       "4         https://www.linkedin.com/jobs/view/4265960423   \n",
       "...                                                 ...   \n",
       "2227      https://www.linkedin.com/jobs/view/4309720429   \n",
       "2228      https://www.linkedin.com/jobs/view/4309719532   \n",
       "2229      https://www.linkedin.com/jobs/view/4309701623   \n",
       "2230      https://www.linkedin.com/jobs/view/4309703481   \n",
       "2231      https://www.linkedin.com/jobs/view/4309718555   \n",
       "\n",
       "                                      title                 company  \\\n",
       "0               Data Engineer/ETL Developer    Princeton IT America   \n",
       "1                       2702- Data Engineer                     EXL   \n",
       "2                             Data Engineer                 SatSure   \n",
       "3                     DevOps/Cloud Engineer        BayOne Solutions   \n",
       "4     AI Developer – Immediate Joiners Only              Perimattic   \n",
       "...                                     ...                     ...   \n",
       "2227                         Data Scientist  People Prime Worldwide   \n",
       "2228                         Data Scientist  People Prime Worldwide   \n",
       "2229                         Data Scientist  People Prime Worldwide   \n",
       "2230        Senior AI Developer - Bangalore                     SAP   \n",
       "2231                  Senior Data Scientist  People Prime Worldwide   \n",
       "\n",
       "                               location scrape_date scrape_time  \n",
       "0                                KA, IN  2025-07-16    12:23:55  \n",
       "1              Pune, Maharashtra, India  2025-07-16    12:23:55  \n",
       "2     Bangalore Urban, Karnataka, India  2025-07-16    12:23:55  \n",
       "3           Bengaluru, Karnataka, India  2025-07-16    12:23:55  \n",
       "4            Mumbai, Maharashtra, India  2025-07-16    12:23:55  \n",
       "...                                 ...         ...         ...  \n",
       "2227        Hyderabad, Telangana, India  2025-10-06    10:23:15  \n",
       "2228        Hyderabad, Telangana, India  2025-10-06    10:23:15  \n",
       "2229        Hyderabad, Telangana, India  2025-10-06    10:23:15  \n",
       "2230        Bengaluru, Karnataka, India  2025-10-06    10:23:15  \n",
       "2231        Hyderabad, Telangana, India  2025-10-06    10:23:15  \n",
       "\n",
       "[2232 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\n",
    "    \"../data/df2_0129.csv\"\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62fcc7",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64aca34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2232 entries, 0 to 2231\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   url          2232 non-null   object\n",
      " 1   title        2232 non-null   object\n",
      " 2   company      2231 non-null   object\n",
      " 3   location     1798 non-null   object\n",
      " 4   scrape_date  2232 non-null   object\n",
      " 5   scrape_time  2232 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 104.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b65970b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2232 entries, 0 to 2231\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   url          2232 non-null   str  \n",
      " 1   title        2232 non-null   str  \n",
      " 2   company      2232 non-null   str  \n",
      " 3   location     2232 non-null   str  \n",
      " 4   scrape_date  2232 non-null   str  \n",
      " 5   scrape_time  2232 non-null   str  \n",
      "dtypes: str(6)\n",
      "memory usage: 104.8 KB\n"
     ]
    }
   ],
   "source": [
    "# location 컬럼의 NaN을 None(또는 빈 문자열 '')으로 미리 채웁니다.\n",
    "data = df.fillna('None')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821ef48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_location(row):\n",
    "    row_str = str(row).strip()\n",
    "    \n",
    "    # 결과값이 'None'이라는 \"글자\"가 되도록 수정\n",
    "    if row_str.lower() in ['none', 'nan', '']:\n",
    "        return pd.Series(['None', 'None', 'None'])\n",
    "    \n",
    "    parts = [p.strip() for p in row_str.split(',')]\n",
    "    \n",
    "    if len(parts) >= 3:\n",
    "        return pd.Series([\", \".join(parts[:-2]), parts[-2], parts[-1]])\n",
    "    elif len(parts) == 2:\n",
    "        # City 자리에 문자열 'None' 배정\n",
    "        return pd.Series(['None', parts[0], parts[1]])\n",
    "    elif len(parts) == 1:\n",
    "        return pd.Series(['None', 'None', parts[0]])\n",
    "    \n",
    "    return pd.Series(['None', 'None', 'None'])\n",
    "\n",
    "# 적용\n",
    "df[['city', 'state', 'country']] = df['location'].apply(align_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280f4fd",
   "metadata": {},
   "source": [
    "## 2-1) 데이터 정보 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a86784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2232 entries, 0 to 2231\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   url          2232 non-null   str  \n",
      " 1   title        2232 non-null   str  \n",
      " 2   company      2231 non-null   str  \n",
      " 3   location     1798 non-null   str  \n",
      " 4   scrape_date  2232 non-null   str  \n",
      " 5   scrape_time  2232 non-null   str  \n",
      " 6   city         2232 non-null   str  \n",
      " 7   state        2232 non-null   str  \n",
      " 8   country      2232 non-null   str  \n",
      "dtypes: str(9)\n",
      "memory usage: 157.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aab43756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Princeton IT America\n",
       "1                          EXL\n",
       "2                      SatSure\n",
       "3             BayOne Solutions\n",
       "4                   Perimattic\n",
       "                 ...          \n",
       "2227    People Prime Worldwide\n",
       "2228    People Prime Worldwide\n",
       "2229    People Prime Worldwide\n",
       "2230                       SAP\n",
       "2231    People Prime Worldwide\n",
       "Name: company, Length: 2232, dtype: str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"company\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0639863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d71c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2231</td>\n",
       "      <td>1798</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2129</td>\n",
       "      <td>758</td>\n",
       "      <td>967</td>\n",
       "      <td>106</td>\n",
       "      <td>26</td>\n",
       "      <td>600</td>\n",
       "      <td>73</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4307968830</td>\n",
       "      <td>Remote Python AI Engineer - 17852</td>\n",
       "      <td>Turing</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>13:55:55</td>\n",
       "      <td>None</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>149</td>\n",
       "      <td>284</td>\n",
       "      <td>434</td>\n",
       "      <td>298</td>\n",
       "      <td>31</td>\n",
       "      <td>742</td>\n",
       "      <td>556</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "count                                            2232   \n",
       "unique                                           2129   \n",
       "top     https://www.linkedin.com/jobs/view/4307968830   \n",
       "freq                                               10   \n",
       "\n",
       "                                    title company  \\\n",
       "count                                2232    2231   \n",
       "unique                                758     967   \n",
       "top     Remote Python AI Engineer - 17852  Turing   \n",
       "freq                                  149     284   \n",
       "\n",
       "                           location scrape_date scrape_time  city      state  \\\n",
       "count                          1798        2232        2232  2232       2232   \n",
       "unique                          106          26         600    73         46   \n",
       "top     Bengaluru, Karnataka, India  2025-07-16    13:55:55  None  Karnataka   \n",
       "freq                            434         298          31   742        556   \n",
       "\n",
       "       country  \n",
       "count     2232  \n",
       "unique       4  \n",
       "top      India  \n",
       "freq      1567  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c3b5b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15208\\702825166.py:1: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  df.describe(include=\"object\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2231</td>\n",
       "      <td>1798</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2129</td>\n",
       "      <td>758</td>\n",
       "      <td>967</td>\n",
       "      <td>106</td>\n",
       "      <td>26</td>\n",
       "      <td>600</td>\n",
       "      <td>73</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4307968830</td>\n",
       "      <td>Remote Python AI Engineer - 17852</td>\n",
       "      <td>Turing</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>13:55:55</td>\n",
       "      <td>None</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>149</td>\n",
       "      <td>284</td>\n",
       "      <td>434</td>\n",
       "      <td>298</td>\n",
       "      <td>31</td>\n",
       "      <td>742</td>\n",
       "      <td>556</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "count                                            2232   \n",
       "unique                                           2129   \n",
       "top     https://www.linkedin.com/jobs/view/4307968830   \n",
       "freq                                               10   \n",
       "\n",
       "                                    title company  \\\n",
       "count                                2232    2231   \n",
       "unique                                758     967   \n",
       "top     Remote Python AI Engineer - 17852  Turing   \n",
       "freq                                  149     284   \n",
       "\n",
       "                           location scrape_date scrape_time  city      state  \\\n",
       "count                          1798        2232        2232  2232       2232   \n",
       "unique                          106          26         600    73         46   \n",
       "top     Bengaluru, Karnataka, India  2025-07-16    13:55:55  None  Karnataka   \n",
       "freq                            434         298          31   742        556   \n",
       "\n",
       "       country  \n",
       "count     2232  \n",
       "unique       4  \n",
       "top      India  \n",
       "freq      1567  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e26ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_job_data_viability(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return False\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 1. 타이틀 존재 여부 확인 (가장 기본)\n",
    "        # <h1>이 없거나 텍스트가 너무 짧으면 공고가 아니라고 판단\n",
    "        title_tag = soup.find('h1')\n",
    "        title_text = title_tag.get_text(strip=True) if title_tag else \"\"\n",
    "        \n",
    "        # 2. 본문 내용 확인 (수집할 Skill, Level 정보가 들어있을 공간)\n",
    "        # 보통 채용 공고는 설명글이 최소 300자 이상입니다.\n",
    "        description_text = soup.get_text()\n",
    "        \n",
    "        # [구별 로직]\n",
    "        # 직무 타이틀이 있고, 본문 내용이 충분히(예: 500자 이상) 있다면 수집 가능으로 판단\n",
    "        if len(title_text) > 2 and len(description_text) > 500:\n",
    "            # 추가 검사: 마감 문구가 없는지 확인\n",
    "            if \"no longer accepting\" in description_text.lower():\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d369eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeed 공고 수: 230\n",
      "LinkedIn 공고 수: 2002\n"
     ]
    }
   ],
   "source": [
    "# Indeed 링크만 뽑기\n",
    "indeed_df = df[df['url'].str.contains('indeed', na=False)]\n",
    "\n",
    "# LinkedIn 링크만 뽑기\n",
    "linkedin_df = df[df['url'].str.contains('linkedin', na=False)]\n",
    "\n",
    "print(f\"Indeed 공고 수: {len(indeed_df)}\")\n",
    "print(f\"LinkedIn 공고 수: {len(linkedin_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f7c48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def check_viability_by_domain(url):\n",
    "    if pd.isna(url) or url == 'None' or url == '':\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # 차단 방지를 위해 일반적인 브라우저 헤더 추가\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return False\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text_content = soup.get_text().lower()\n",
    "\n",
    "        if 'linkedin.com' in url:\n",
    "            if \"no longer accepting\" in text_content:\n",
    "                return False\n",
    "            return soup.find('h1') is not None\n",
    "\n",
    "        elif 'indeed.com' in url:\n",
    "            if \"job expired\" in text_content or \"not found\" in text_content:\n",
    "                return False\n",
    "            return soup.find('h1') is not None\n",
    "\n",
    "        else:\n",
    "            return len(text_content) > 500\n",
    "\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0580842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 샘플 테스트 진행 중 ---\n",
      "Indeed 결과: False\n",
      "LinkedIn 결과: True\n"
     ]
    }
   ],
   "source": [
    "# 샘플 데이터 추출 및 테스트\n",
    "# na=False를 넣어 에러를 방지합니다.\n",
    "sample_indeed = df[df['url'].str.contains('indeed', na=False)]['url'].iloc[0]\n",
    "sample_linkedin = df[df['url'].str.contains('linkedin', na=False)]['url'].iloc[0]\n",
    "\n",
    "print(\"--- 샘플 테스트 진행 중 ---\")\n",
    "res_indeed = check_viability_by_domain(sample_indeed)\n",
    "res_linkedin = check_viability_by_domain(sample_linkedin)\n",
    "\n",
    "print(f\"Indeed 결과: {res_indeed}\")\n",
    "print(f\"LinkedIn 결과: {res_linkedin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adf28fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP 상태 코드: 403\n",
      "------------------------------\n",
      "페이지 텍스트 앞부분 (500자):\n",
      "Find jobs   Company Reviews   Find salaries    Sign in       Upload your resume   Sign in   Employers / Post Job   Find jobs   Company Reviews   Find salaries      Additional Verification Required  Enable JavaScript and cookies to continue Return home   → Troubleshooting Cloudflare Errors Need more help? Contact us\n",
      "------------------------------\n",
      "h1 태그 발견 여부: True\n",
      "h1 내용: Additional Verification Required\n"
     ]
    }
   ],
   "source": [
    "# Indeed 샘플 하나만 집중 분석\n",
    "sample_indeed_url = df[df['url'].str.contains('indeed', na=False)]['url'].iloc[0]\n",
    "\n",
    "def debug_indeed(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        print(f\"HTTP 상태 코드: {response.status_code}\")\n",
    "        print(\"-\" * 30)\n",
    "        print(\"페이지 텍스트 앞부분 (500자):\")\n",
    "        print(soup.get_text()[:500].strip())\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # h1이 정말 없는지 확인\n",
    "        h1 = soup.find('h1')\n",
    "        print(f\"h1 태그 발견 여부: {h1 is not None}\")\n",
    "        if h1: print(f\"h1 내용: {h1.get_text()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"에러 발생: {e}\")\n",
    "\n",
    "debug_indeed(sample_indeed_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2517344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeed 결과: Blocked/Verification Required\n"
     ]
    }
   ],
   "source": [
    "def check_viability_with_block_detect(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/110.0.0.0 Safari/537.36'}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        # Cloudflare에 걸린 경우\n",
    "        if response.status_code == 403 or \"cloudflare\" in response.text.lower():\n",
    "            return \"Blocked/Verification Required\"\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # LinkedIn 통과 로직 (이미 성공 확인됨)\n",
    "        if 'linkedin.com' in url:\n",
    "            if \"no longer accepting\" in soup.get_text().lower():\n",
    "                return \"Closed\"\n",
    "            return \"Exist\" if soup.find('h1') else \"No Title\"\n",
    "\n",
    "        # Indeed가 운 좋게 200 OK를 줬을 경우\n",
    "        elif 'indeed.com' in url:\n",
    "            if \"job expired\" in soup.get_text().lower():\n",
    "                return \"Closed\"\n",
    "            return \"Exist\" if soup.find('h1') else \"No Title\"\n",
    "\n",
    "        return \"Unknown\"\n",
    "    except:\n",
    "        return \"Error/Timeout\"\n",
    "\n",
    "# 샘플 재테스트\n",
    "print(f\"Indeed 결과: {check_viability_with_block_detect(sample_indeed_url)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bffec2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2232 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2232/2232 [1:00:03<00:00,  1.61s/it]  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def stable_check(url):\n",
    "    if 'indeed.com' in url:\n",
    "        return \"Blocked (Indeed)\"\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/110.0.0.0 Safari/537.36'}\n",
    "    \n",
    "    # 최대 3번까지 재시도\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            # 서버를 속이기 위한 랜덤한 휴식 (0.5초 ~ 1.5초)\n",
    "            time.sleep(random.uniform(0.5, 1.5))\n",
    "            \n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                text = response.text.lower()\n",
    "                if \"no longer accepting\" in text: return \"Closed\"\n",
    "                return \"Exist\" if \"h1\" in text else \"No Title\"\n",
    "            \n",
    "            elif response.status_code == 429:\n",
    "                # 429 에러 시 더 오래 대기 후 재시도\n",
    "                wait_time = (attempt + 1) * 5\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "                \n",
    "            return f\"Error ({response.status_code})\"\n",
    "            \n",
    "        except:\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "            \n",
    "    return \"Timeout/Error\"\n",
    "\n",
    "# [핵심] 쓰레드 수를 5개 이하로 줄여서 천천히 보냅니다.\n",
    "urls = df['url'].tolist()\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # 기존 코드 유지 (상태를 상세히 기록)\n",
    "        df['exist_status'] = list(tqdm(executor.map(stable_check, urls), total=len(urls)))\n",
    "\n",
    "        # 협업자를 위한 직관적인 Bool 컬럼 추가\n",
    "        # 'Exist'인 경우만 True, 나머지는 접속 불가(False)로 간주\n",
    "        df['is_accessible'] = df['exist_status'] == 'Exist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35d70224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exist_status\n",
       "Exist               1777\n",
       "Blocked (Indeed)     230\n",
       "Closed               105\n",
       "Error (404)          105\n",
       "Timeout/Error         15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"exist_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c983e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blocked (Indeed)' 'Exist' 'Exist' ... 'Exist' 'Exist' 'Exist']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"exist_status\"].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85b09efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"exist_status\"].__contains__(\"Exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f96138d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "존재 건수:                                                 url  \\\n",
      "1     https://www.linkedin.com/jobs/view/4265959832   \n",
      "2     https://www.linkedin.com/jobs/view/4267652354   \n",
      "3     https://www.linkedin.com/jobs/view/4267647369   \n",
      "4     https://www.linkedin.com/jobs/view/4265960423   \n",
      "5     https://www.linkedin.com/jobs/view/4267649182   \n",
      "...                                             ...   \n",
      "2227  https://www.linkedin.com/jobs/view/4309720429   \n",
      "2228  https://www.linkedin.com/jobs/view/4309719532   \n",
      "2229  https://www.linkedin.com/jobs/view/4309701623   \n",
      "2230  https://www.linkedin.com/jobs/view/4309703481   \n",
      "2231  https://www.linkedin.com/jobs/view/4309718555   \n",
      "\n",
      "                                      title                 company  \\\n",
      "1                       2702- Data Engineer                     EXL   \n",
      "2                             Data Engineer                 SatSure   \n",
      "3                     DevOps/Cloud Engineer        BayOne Solutions   \n",
      "4     AI Developer – Immediate Joiners Only              Perimattic   \n",
      "5                        GCP Cloud Engineer  People Prime Worldwide   \n",
      "...                                     ...                     ...   \n",
      "2227                         Data Scientist  People Prime Worldwide   \n",
      "2228                         Data Scientist  People Prime Worldwide   \n",
      "2229                         Data Scientist  People Prime Worldwide   \n",
      "2230        Senior AI Developer - Bangalore                     SAP   \n",
      "2231                  Senior Data Scientist  People Prime Worldwide   \n",
      "\n",
      "                               location scrape_date scrape_time  \\\n",
      "1              Pune, Maharashtra, India  2025-07-16    12:23:55   \n",
      "2     Bangalore Urban, Karnataka, India  2025-07-16    12:23:55   \n",
      "3           Bengaluru, Karnataka, India  2025-07-16    12:23:55   \n",
      "4            Mumbai, Maharashtra, India  2025-07-16    12:23:55   \n",
      "5           Bengaluru, Karnataka, India  2025-07-16    12:23:55   \n",
      "...                                 ...         ...         ...   \n",
      "2227        Hyderabad, Telangana, India  2025-10-06    10:23:15   \n",
      "2228        Hyderabad, Telangana, India  2025-10-06    10:23:15   \n",
      "2229        Hyderabad, Telangana, India  2025-10-06    10:23:15   \n",
      "2230        Bengaluru, Karnataka, India  2025-10-06    10:23:15   \n",
      "2231        Hyderabad, Telangana, India  2025-10-06    10:23:15   \n",
      "\n",
      "                 city        state country exist_status  \n",
      "1                Pune  Maharashtra   India        Exist  \n",
      "2     Bangalore Urban    Karnataka   India        Exist  \n",
      "3           Bengaluru    Karnataka   India        Exist  \n",
      "4              Mumbai  Maharashtra   India        Exist  \n",
      "5           Bengaluru    Karnataka   India        Exist  \n",
      "...               ...          ...     ...          ...  \n",
      "2227        Hyderabad    Telangana   India        Exist  \n",
      "2228        Hyderabad    Telangana   India        Exist  \n",
      "2229        Hyderabad    Telangana   India        Exist  \n",
      "2230        Bengaluru    Karnataka   India        Exist  \n",
      "2231        Hyderabad    Telangana   India        Exist  \n",
      "\n",
      "[1776 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "exist_rows = df[df['exist_status'] == \"Exist\"]\n",
    "print(f\"존재 건수: {exist_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6f84e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에러 발생 건수:                                                 url  \\\n",
      "49    https://www.linkedin.com/jobs/view/4267655980   \n",
      "186   https://www.linkedin.com/jobs/view/4265992400   \n",
      "325   https://www.linkedin.com/jobs/view/4266934948   \n",
      "542   https://www.linkedin.com/jobs/view/4268718547   \n",
      "646   https://www.linkedin.com/jobs/view/4270437429   \n",
      "746   https://www.linkedin.com/jobs/view/4302884599   \n",
      "854   https://www.linkedin.com/jobs/view/4302785762   \n",
      "906   https://www.linkedin.com/jobs/view/4257182328   \n",
      "1044  https://www.linkedin.com/jobs/view/4304161032   \n",
      "1047  https://www.linkedin.com/jobs/view/4304142990   \n",
      "1083  https://www.linkedin.com/jobs/view/4304611493   \n",
      "1134  https://www.linkedin.com/jobs/view/4304020956   \n",
      "1434  https://www.linkedin.com/jobs/view/4306467707   \n",
      "1574  https://www.linkedin.com/jobs/view/4305329702   \n",
      "1633  https://www.linkedin.com/jobs/view/4308046019   \n",
      "1782  https://www.linkedin.com/jobs/view/4306530506   \n",
      "1800  https://www.linkedin.com/jobs/view/4308993936   \n",
      "1878  https://www.linkedin.com/jobs/view/4309359319   \n",
      "1965  https://www.linkedin.com/jobs/view/4308577020   \n",
      "1985  https://www.linkedin.com/jobs/view/4308587857   \n",
      "\n",
      "                                                  title  \\\n",
      "49                               Senior DevOps Engineer   \n",
      "186                 Data Engineer-Business Intelligence   \n",
      "325                                   GCP Data Engineer   \n",
      "542                                   GCP Data Engineer   \n",
      "646                                 Data Analyst Intern   \n",
      "746                        Data Scientist (with Python)   \n",
      "854                            AI Engineer (Automotive)   \n",
      "906                                AI Devops Consultant   \n",
      "1044                         Python AI Engineer - 17852   \n",
      "1047                         Python AI Engineer - 17852   \n",
      "1083                                    Gen AI Engineer   \n",
      "1134  AI Developer (Deep Learning, Computer Vision &...   \n",
      "1434                                       AI Scientist   \n",
      "1574                             Generative AI Engineer   \n",
      "1633                  Remote Python AI Engineer - 17852   \n",
      "1782                              Senior Data Scientist   \n",
      "1800                  Remote Python AI Engineer - 17852   \n",
      "1878                                       Data Analyst   \n",
      "1965                                    Gen AI Engineer   \n",
      "1985                                        AI Engineer   \n",
      "\n",
      "                                   company                           location  \\\n",
      "49          CG-VAK Software & Exports Ltd.      Coimbatore, Tamil Nadu, India   \n",
      "186                                    IBM           Pune, Maharashtra, India   \n",
      "325                          Dataquad Inc.        Hyderabad, Telangana, India   \n",
      "542      Asv Consulting Services Pvt. Ltd.           Pune, Maharashtra, India   \n",
      "646               WebBoost Solutions by UM                                NaN   \n",
      "746                       MyRemoteTeam Inc        Bengaluru, Karnataka, India   \n",
      "854                                Infosys   Bengaluru East, Karnataka, India   \n",
      "906                                 Oracle         Chennai, Tamil Nadu, India   \n",
      "1044                                Turing           Pune, Maharashtra, India   \n",
      "1047                                Turing           Gurugram, Haryana, India   \n",
      "1083                     Jase HR Solutions        Bengaluru, Karnataka, India   \n",
      "1134  Blue Cloud Softech Solutions Limited  Bangalore Urban, Karnataka, India   \n",
      "1434                               Qure.ai        Bengaluru, Karnataka, India   \n",
      "1574                              Apptware           Pune, Maharashtra, India   \n",
      "1633                                Turing                                NaN   \n",
      "1782                               Virtusa         Chennai, Tamil Nadu, India   \n",
      "1800                                Turing      Coimbatore, Tamil Nadu, India   \n",
      "1878                                Uplers                                NaN   \n",
      "1965                             Cognizant        Hyderabad, Telangana, India   \n",
      "1985                               Uplevyl        Noida, Uttar Pradesh, India   \n",
      "\n",
      "     scrape_date scrape_time             city          state country  \\\n",
      "49    2025-07-16    12:45:54       Coimbatore     Tamil Nadu   India   \n",
      "186   2025-07-16    11:56:42             Pune    Maharashtra   India   \n",
      "325   2025-07-17    07:43:52        Hyderabad      Telangana   India   \n",
      "542   2025-07-18    07:24:36             Pune    Maharashtra   India   \n",
      "646   2025-07-20    18:30:14             None           None    None   \n",
      "746   2025-09-19    10:25:17        Bengaluru      Karnataka   India   \n",
      "854   2025-09-19    18:28:18   Bengaluru East      Karnataka   India   \n",
      "906   2025-09-20    14:38:28          Chennai     Tamil Nadu   India   \n",
      "1044  2025-09-22    16:27:02             Pune    Maharashtra   India   \n",
      "1047  2025-09-22    16:27:02         Gurugram        Haryana   India   \n",
      "1083  2025-09-23    03:34:17        Bengaluru      Karnataka   India   \n",
      "1134  2025-09-23    12:41:42  Bangalore Urban      Karnataka   India   \n",
      "1434  2025-09-26    09:22:23        Bengaluru      Karnataka   India   \n",
      "1574  2025-09-29    11:17:13             Pune    Maharashtra   India   \n",
      "1633  2025-09-29    15:21:18             None           None    None   \n",
      "1782  2025-10-01    14:20:56          Chennai     Tamil Nadu   India   \n",
      "1800  2025-10-01    15:40:44       Coimbatore     Tamil Nadu   India   \n",
      "1878  2025-10-02    12:56:32             None           None    None   \n",
      "1965  2025-10-03    09:39:21        Hyderabad      Telangana   India   \n",
      "1985  2025-10-03    13:43:08            Noida  Uttar Pradesh   India   \n",
      "\n",
      "       exist_status  \n",
      "49    Timeout/Error  \n",
      "186   Timeout/Error  \n",
      "325   Timeout/Error  \n",
      "542   Timeout/Error  \n",
      "646   Timeout/Error  \n",
      "746   Timeout/Error  \n",
      "854   Timeout/Error  \n",
      "906   Timeout/Error  \n",
      "1044  Timeout/Error  \n",
      "1047  Timeout/Error  \n",
      "1083  Timeout/Error  \n",
      "1134  Timeout/Error  \n",
      "1434  Timeout/Error  \n",
      "1574  Timeout/Error  \n",
      "1633  Timeout/Error  \n",
      "1782  Timeout/Error  \n",
      "1800  Timeout/Error  \n",
      "1878  Timeout/Error  \n",
      "1965  Timeout/Error  \n",
      "1985  Timeout/Error  \n"
     ]
    }
   ],
   "source": [
    "error_rows = df[df['exist_status'] == \"Timeout/Error\"]\n",
    "print(f\"에러 발생 건수: {error_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dd150e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "채용 마감 건수:                                                 url  \\\n",
      "16    https://www.linkedin.com/jobs/view/4265957121   \n",
      "74    https://www.linkedin.com/jobs/view/4267656919   \n",
      "76    https://www.linkedin.com/jobs/view/4267660365   \n",
      "88    https://www.linkedin.com/jobs/view/4267667352   \n",
      "95    https://www.linkedin.com/jobs/view/4267668395   \n",
      "...                                             ...   \n",
      "2167  https://www.linkedin.com/jobs/view/4308356816   \n",
      "2175  https://www.linkedin.com/jobs/view/4310629261   \n",
      "2182  https://www.linkedin.com/jobs/view/4310678136   \n",
      "2183  https://www.linkedin.com/jobs/view/4310678354   \n",
      "2224  https://www.linkedin.com/jobs/view/4308719932   \n",
      "\n",
      "                                         title  \\\n",
      "16                Senior DevOps Engineer – GCP   \n",
      "74        AI Specialist – AI Agent Development   \n",
      "76                              Cloud Engineer   \n",
      "88    AI Engineer – Autonomous Agent Developer   \n",
      "95                   Gen AI Engineer+.Net Core   \n",
      "...                                        ...   \n",
      "2167                             AI Researcher   \n",
      "2175                              AI Developer   \n",
      "2182                       Agentic AI Engineer   \n",
      "2183                               AI Engineer   \n",
      "2224              Sr Machine Learning Engineer   \n",
      "\n",
      "                                 company                     location  \\\n",
      "16              Celestibia Solutions Pvt     Pune, Maharashtra, India   \n",
      "74                            Brand Raga  Bengaluru, Karnataka, India   \n",
      "76                          Workforce247    Ahmedabad, Gujarat, India   \n",
      "88                   SpacePepper Studios      New Delhi, Delhi, India   \n",
      "95               NTek Software Solutions  Hyderabad, Telangana, India   \n",
      "...                                  ...                          ...   \n",
      "2167                           BraneMind   Mumbai, Maharashtra, India   \n",
      "2175  Daply | Scaling Digital Publishing                          NaN   \n",
      "2182           Supertech Innovation Labs      New Delhi, Delhi, India   \n",
      "2183                  MagickTech Pvt Ltd   Chennai, Tamil Nadu, India   \n",
      "2224                              PayPal  Bengaluru, Karnataka, India   \n",
      "\n",
      "     scrape_date scrape_time       city        state country exist_status  \n",
      "16    2025-07-16    12:25:03       Pune  Maharashtra   India       Closed  \n",
      "74    2025-07-16    13:04:22  Bengaluru    Karnataka   India       Closed  \n",
      "76    2025-07-16    13:07:10  Ahmedabad      Gujarat   India       Closed  \n",
      "88    2025-07-16    13:19:20  New Delhi        Delhi   India       Closed  \n",
      "95    2025-07-16    13:30:05  Hyderabad    Telangana   India       Closed  \n",
      "...          ...         ...        ...          ...     ...          ...  \n",
      "2167  2025-10-04    22:17:33     Mumbai  Maharashtra   India       Closed  \n",
      "2175  2025-10-05    08:41:33       None         None    None       Closed  \n",
      "2182  2025-10-05    11:15:01  New Delhi        Delhi   India       Closed  \n",
      "2183  2025-10-05    12:37:35    Chennai   Tamil Nadu   India       Closed  \n",
      "2224  2025-10-06    09:24:43  Bengaluru    Karnataka   India       Closed  \n",
      "\n",
      "[102 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "close_rows = df[df['exist_status'] == \"Closed\"]\n",
    "print(f\"채용 마감 건수: {close_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac31b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"순차적 URL 체크 시작 (안전 모드)...\")\n",
    "\n",
    "# iterrows를 사용하여 하나씩 확실하게 처리\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    url = row['url']\n",
    "    \n",
    "    # 1. Indeed는 어차피 안 되니 바로 패스\n",
    "    if 'indeed.com' in str(url):\n",
    "        results.append(\"Blocked (Indeed)\")\n",
    "        continue\n",
    "    \n",
    "    # 2. LinkedIn 및 기타 사이트 처리\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/110.0.0.0 Safari/537.36'}\n",
    "        # 랜덤 지연을 주어 사람처럼 행동 (0.3 ~ 0.8초)\n",
    "        time.sleep(random.uniform(0.3, 0.8))\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            text = response.text.lower()\n",
    "            if \"no longer accepting\" in text:\n",
    "                results.append(\"Closed\")\n",
    "            elif \"h1\" in text:\n",
    "                results.append(\"Exist\")\n",
    "            else:\n",
    "                results.append(\"No Title\")\n",
    "        else:\n",
    "            results.append(f\"Error ({response.status_code})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        results.append(\"Timeout/Error\")\n",
    "\n",
    "# 최종 결과 저장\n",
    "df['exist_status'] = results\n",
    "print(df['exist_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2dc2f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 페이지 제목: Senior DevOps Engineer | CG-VAK Software & Exports Ltd. | LinkedIn\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "# [핵심] 9222 포트로 열려 있는 브라우저에 접속하겠다는 설정\n",
    "options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "\n",
    "# 이제 새 창을 띄우는 게 아니라 기존 창을 잡습니다.\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# 3. 테스트: 이제 URL 이동이 될 겁니다!\n",
    "target_url = \"https://www.linkedin.com/jobs/view/4267655980\"\n",
    "driver.get(target_url)\n",
    "\n",
    "print(\"현재 페이지 제목:\", driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a89679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 더보기 버튼 클릭 성공\n",
      "{'회사명': 'CG-VAK Software & Exports Ltd.', '포지션': 'Senior DevOps Engineer', '국가': 'Coimbatore, Tamil Nadu, India', '지원자수': '25 applicants', '채용공고정보': 'About the job\\nGood exposure on Agile Methodology in designing and implementation of\\nContinuous Integration and Delivery (CI/CD).\\n• Strong understanding of DevOps Principles and Practices.\\n• Led the Migration of On-Premises Infrastructure to Cloud, Cloud Migrations\\nresulting reduction in operational costs and improved scalability.\\n• Good understanding of AWS Services like EC2, S3, IAM, RDS, Secret Manager\\nServer, API Gateway, Docker, Kubernetes Services and Monitoring Tools.\\n• Expertise in Terraform, Cloud Formation Templates and Bash and Python\\nScripting for automation of technical activities in AWS.\\n• Expertise in Build and Release deployments.\\n• Experience on Code Quality Analysis using SonarQube.\\n• Good understanding of programming languages like Java, Python and YAML.\\n• Collaborated with cross-functional teams to ensure compliance with Security\\nStandards and best practices in cloud environments.\\n• Expertise in automation deployment, scaling, and monitoring of cloud resources.\\n• Experience in implementing and managing cloud-native solutions.\\n• Managed environments DEV, QA, Release and PROD for various releases and\\ndesigned instance.\\n• Expertise on Backup/Recovery Services.\\n• Good Interpersonal Skills, Client relationship management, takes initiatives,\\nproactive in solving problems and providing best solutions.\\n• Passionate about leveraging cutting-edge technologies to drive innovation and\\ndeliver business value in cloud operations\\nRequirements added by the job poster\\n• 4+ years of work experience with DevOps'}\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import random\n",
    "\n",
    "def collect_with_user_selectors(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(random.uniform(5, 7)) # 로딩 시간을 충분히 줍니다.\n",
    "\n",
    "    try:\n",
    "        # 1. 더보기 버튼 클릭 (이걸 눌러야 '채용공고 정보'가 확장됨)\n",
    "        # 보내주신 더보기 SELECTOR 적용\n",
    "        more_btn_selector = \"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._84ec64af > div:nth-child(3) > div > div > div > div > div > div > p:nth-child(3) > span > button\"\n",
    "        \n",
    "        try:\n",
    "            more_btn = driver.find_element(By.CSS_SELECTOR, more_btn_selector)\n",
    "            driver.execute_script(\"arguments[0].click();\", more_btn)\n",
    "            time.sleep(1.5)\n",
    "            print(\"✅ 더보기 버튼 클릭 성공\")\n",
    "        except:\n",
    "            print(\"⚠️ 더보기 버튼을 찾을 수 없거나 이미 확장됨\")\n",
    "\n",
    "        # 2. 각 항목 수집 (사용자님이 찾으신 SELECTOR 그대로 대입)\n",
    "        results = {\n",
    "            '회사명': driver.find_element(By.CSS_SELECTOR, \"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._45232ba5 > div.f00f2910.bbf46644.dc1dbfb7._4fe97c09._949bca74._39dfa905 > a > div > p > a\").text.strip(),\n",
    "            \n",
    "            '포지션': driver.find_element(By.CSS_SELECTOR, \"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._45232ba5 > div.f00f2910.bbf46644._616f5abe._4fe97c09._949bca74._39dfa905 > div > p\").text.strip(),\n",
    "            \n",
    "            '국가': driver.find_element(By.CSS_SELECTOR, \"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._45232ba5 > p > span:nth-child(1)\").text.strip(),\n",
    "            \n",
    "            '지원자수': driver.find_element(By.CSS_SELECTOR, \"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._45232ba5 > p > span:nth-child(7)\").text.strip(),\n",
    "            \n",
    "            '채용공고정보': driver.find_element(By.CSS_SELECTOR, \"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._84ec64af > div:nth-child(3) > div > div > div > div > div > div\").text.strip()\n",
    "        }\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 수집 에러: {e}\")\n",
    "        return None\n",
    "\n",
    "# 실행\n",
    "print(collect_with_user_selectors(driver, \"https://www.linkedin.com/jobs/view/4267655980\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30f33bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 SyntaxError 수정 완료! 10개 수집을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:19<00:00,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 완료! 'jobs_test_10_samples_final.csv' 파일을 확인해 보세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 1. 새 컬럼 초기화\n",
    "new_columns = ['crl_company_nm', 'crl_position', 'crl_country', 'crl_napply', \n",
    "               'crl_work_type', 'crl_emp_type', 'crl_jd', 'crl_requirement']\n",
    "\n",
    "for col in new_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "# 2. 안전한 데이터 추출 함수\n",
    "def safe_get(selector):\n",
    "    try:\n",
    "        element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "        return element.text.strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# 3. 10개 테스트 진행\n",
    "test_indices = df.index[:10]\n",
    "output_test_file = \"jobs_test_10_samples_final.csv\"\n",
    "\n",
    "print(\"🚀 SyntaxError 수정 완료! 10개 수집을 시작합니다...\")\n",
    "\n",
    "for idx in tqdm(test_indices):\n",
    "    url = df.at[idx, 'url']\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(5, 7)) \n",
    "        \n",
    "        # 더보기 버튼 클릭 (유연한 셀렉터)\n",
    "        try:\n",
    "            more_btn = driver.find_element(By.CSS_SELECTOR, \"button[aria-label*='show more'], .jobs-description__footer-button\")\n",
    "            driver.execute_script(\"arguments[0].click();\", more_btn)\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            driver.execute_script(\"window.scrollTo(0, 500);\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        # 각 항목 데이터 매칭 (긴 셀렉터들을 안전하게 감쌌습니다)\n",
    "        df.at[idx, 'crl_company_nm'] = safe_get(\"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._45232ba5 > div.f00f2910.bbf46644.dc1dbfb7._4fe97c09._949bca74._39dfa905 > a > div > p > a\")\n",
    "        \n",
    "        df.at[idx, 'crl_position'] = safe_get(\"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._45232ba5 > div.f00f2910.bbf46644._616f5abe._4fe97c09._949bca74._39dfa905 > div > p\")\n",
    "        \n",
    "        df.at[idx, 'crl_country'] = safe_get(\"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._45232ba5 > p > span:nth-child(1)\")\n",
    "        \n",
    "        df.at[idx, 'crl_napply'] = safe_get(\"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._45232ba5 > p > span:nth-child(7)\")\n",
    "        \n",
    "        df.at[idx, 'crl_work_type'] = safe_get(\"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.f00f2910.bbf46644._616f5abe.c77e551a.ce992032.eee86998 > div:nth-child(1) > button > span > span\")\n",
    "        \n",
    "        df.at[idx, 'crl_emp_type'] = safe_get(\"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._39dfa905 > div > div > div.b5d06882 > div > div.f00f2910.bbf46644._616f5abe.c77e551a.ce992032.eee86998 > div:nth-child(2) > button > span > span\")\n",
    "\n",
    "        # JD 수집 (백업 로직 포함)\n",
    "        jd_selector = \"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._84ec64af > div:nth-child(3) > div > div > div > div > div > div > p:nth-child(3) > span\"\n",
    "        jd_content = safe_get(jd_selector)\n",
    "        if len(jd_content) < 50: \n",
    "            jd_content = safe_get(\"#job-details, .jobs-description__content\")\n",
    "        df.at[idx, 'crl_jd'] = jd_content\n",
    "\n",
    "        # 요구사항 수집\n",
    "        req_selector = \"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._84ec64af > div:nth-child(3) > div > div > div > div > div > div > p:nth-child(6)\"\n",
    "        df.at[idx, 'crl_requirement'] = safe_get(req_selector)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Index {idx} 에러: {e}\")\n",
    "\n",
    "# 결과 저장\n",
    "df.iloc[:10].to_csv(output_test_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"✅ 테스트 완료! '{output_test_file}' 파일을 확인해 보세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb414f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 스크롤 및 더보기 로직을 풀가동하여 수집을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:03<00:00,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 스크롤 보정 완료! 'jobs_test_result_scrolled.csv'를 확인해 보세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 1. 새 컬럼 초기화\n",
    "new_columns = ['crl_company_nm', 'crl_position', 'crl_country', 'crl_napply', \n",
    "               'crl_work_type', 'crl_emp_type', 'crl_jd', 'crl_requirement']\n",
    "for col in new_columns:\n",
    "    if col not in df.columns: df[col] = None\n",
    "\n",
    "def safe_get(selector):\n",
    "    try:\n",
    "        return driver.find_element(By.CSS_SELECTOR, selector).text.strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# 3. 테스트 진행\n",
    "test_indices = df.index[:10]\n",
    "output_test_file = \"jobs_test_result_scrolled.csv\"\n",
    "\n",
    "print(\"🚀 스크롤 및 더보기 로직을 풀가동하여 수집을 시작합니다...\")\n",
    "\n",
    "for idx in tqdm(test_indices):\n",
    "    url = df.at[idx, 'url']\n",
    "    if \"indeed.com\" in url: continue\n",
    "        \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(4, 5)) # 초기 로딩 대기\n",
    "\n",
    "        # [핵심] 스크롤 로직 복구 및 강화\n",
    "        # 1단계: 페이지 중간 지점까지 스크롤하여 JD 로딩 유도\n",
    "        driver.execute_script(\"window.scrollTo(0, 800);\")\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        # 2단계: '더보기' 버튼 찾아서 클릭\n",
    "        try:\n",
    "            more_btn = driver.find_element(By.CSS_SELECTOR, \"button[aria-label*='show more'], .jobs-description__footer-button\")\n",
    "            driver.execute_script(\"arguments[0].click();\", more_btn)\n",
    "            time.sleep(1.5) # 더보기 클릭 후 내용 확장 대기\n",
    "        except:\n",
    "            # 버튼이 없는 경우를 대비해 조금 더 아래로 스크롤\n",
    "            driver.execute_script(\"window.scrollTo(0, 1200);\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        # --- 데이터 수집 ---\n",
    "        df.at[idx, 'crl_position'] = safe_get(\"h1.t-24\")\n",
    "        df.at[idx, 'crl_company_nm'] = safe_get(\".job-details-jobs-breadcrumb__container a\")\n",
    "        \n",
    "        # JD 수집 (우선순위 기반)\n",
    "        jd_selectors = [\"#job-details\", \".jobs-description__content\", \".jobs-box__html-content\"]\n",
    "        final_jd = \"\"\n",
    "        for s in jd_selectors:\n",
    "            content = safe_get(s)\n",
    "            if len(content) > 100:\n",
    "                final_jd = content\n",
    "                break\n",
    "        \n",
    "        df.at[idx, 'crl_jd'] = final_jd\n",
    "        # 만약 특정 requirement 위치를 고수하고 싶다면 여기에 다시 추가 가능합니다.\n",
    "        df.at[idx, 'crl_requirement'] = safe_get(\"#workspace > div > div > div.bbb811b2.c27ad205.b1f1d4b1 > div > div > div > div.c07bae8d.f00f2910._85ca723a._616f5abe.c77e551a._949bca74._84ec64af > div:nth-child(3) > div > div > div > div > div > div > p:nth-child(6)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Index {idx} 오류: {e}\")\n",
    "\n",
    "# 저장\n",
    "df.iloc[:10].to_csv(output_test_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"✅ 스크롤 보정 완료! '{output_test_file}'를 확인해 보세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f08400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 고정 셀렉터를 버리고 유연한 셀렉터로 수집을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:28<00:00,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 수집 완료! 'jobs_test_result_final_fixed.csv'에서 crl_jd 열을 확인해 보세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 1. 새 컬럼 초기화\n",
    "new_columns = ['crl_company_nm', 'crl_position', 'crl_country', 'crl_napply', \n",
    "               'crl_work_type', 'crl_emp_type', 'crl_jd', 'crl_requirement']\n",
    "for col in new_columns:\n",
    "    if col not in df.columns: df[col] = None\n",
    "\n",
    "def safe_get(selector):\n",
    "    try:\n",
    "        return driver.find_element(By.CSS_SELECTOR, selector).text.strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# 3. 10개 테스트 진행\n",
    "test_indices = df.index[:10]\n",
    "output_test_file = \"jobs_test_result_fixed_v4.csv\"\n",
    "\n",
    "print(\"🔍 태그 구조 변화를 감지했습니다. JD 완벽 수집을 시작합니다...\")\n",
    "\n",
    "for idx in tqdm(test_indices):\n",
    "    url = df.at[idx, 'url']\n",
    "    if \"indeed.com\" in url: continue\n",
    "        \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(6, 8)) # 로딩 대기\n",
    "\n",
    "        # [스크롤 & 더보기] 텍스트 기반으로 확실하게 클릭\n",
    "        driver.execute_script(\"window.scrollTo(0, 600);\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        click_js = \"\"\"\n",
    "        var elements = document.querySelectorAll('button, span');\n",
    "        for (var el of elements) {\n",
    "            if (el.innerText.trim() === 'See more' || el.innerText.trim() === 'Show more') {\n",
    "                el.click();\n",
    "                return true;\n",
    "            }\n",
    "        }\n",
    "        return false;\n",
    "        \"\"\"\n",
    "        driver.execute_script(click_js)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # [데이터 수집]\n",
    "        df.at[idx, 'crl_position'] = safe_get(\"h1\") \n",
    "        df.at[idx, 'crl_company_nm'] = safe_get(\".job-details-jobs-breadcrumb__container a\")\n",
    "        \n",
    "        # [핵심 보정] JD 수집\n",
    "        # 사용자님이 보여주신 ul/li 태그는 모두 '#job-details'라는 ID 박스 안에 포함됩니다.\n",
    "        # 따라서 이 ID 하나만 제대로 긁으면 p든 ul이든 상관없이 모든 텍스트가 들어옵니다.\n",
    "        \n",
    "        jd_selectors = [\n",
    "            \"#job-details\",                            # 가장 표준적인 본문 박스\n",
    "            \".jobs-description__content\",              # 대안 클래스 1\n",
    "            \".show-more-less-html__markup\"             # 대안 클래스 2 (비로그인용)\n",
    "        ]\n",
    "        \n",
    "        final_jd = \"\"\n",
    "        for s in jd_selectors:\n",
    "            content = safe_get(s)\n",
    "            if len(content) > 100:\n",
    "                final_jd = content\n",
    "                break\n",
    "        \n",
    "        df.at[idx, 'crl_jd'] = final_jd\n",
    "        # Requirement는 따로 긁기보다 JD 전체를 확보하는 데 집중합니다.\n",
    "        df.at[idx, 'crl_requirement'] = \"JD 본문 참조\" if final_jd else \"N/A\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Index {idx} 에러: {e}\")\n",
    "\n",
    "# 저장\n",
    "df.iloc[:10].to_csv(output_test_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"✅ 수집 완료! '{output_test_file}'를 확인해 보세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b86d2",
   "metadata": {},
   "source": [
    "📌 확인 포인트  \n",
    "- 어떤 컬럼이 범주형 데이터인지 확인  \n",
    "- 결측치가 있는 컬럼이 무엇인지 확인  \n",
    "- 금액 데이터 분포가 자연스러운지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878bf10",
   "metadata": {},
   "source": [
    "## 3) 데이터 결측치 파악 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71154420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                   0\n",
       "title                 0\n",
       "company               1\n",
       "location            434\n",
       "scrape_date           0\n",
       "scrape_time           0\n",
       "city                  0\n",
       "state                 0\n",
       "country               0\n",
       "    exist_status      0\n",
       "exist_status          0\n",
       "is_accessible         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772590cc",
   "metadata": {},
   "source": [
    "## 4) 데이터 이상치 파악 및 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b51b8a",
   "metadata": {},
   "source": [
    "## 5) 파생 변수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0594c90",
   "metadata": {},
   "source": [
    "## 6) 전처리 데이터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a9459",
   "metadata": {},
   "source": [
    "# 3. 데이터 탐색하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e8b41",
   "metadata": {},
   "source": [
    "## 3-1) 컬럼 탐색하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f186f",
   "metadata": {},
   "source": [
    "### 3-1-1. 변수별로 특징 파악하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ca380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "core_skills\n",
       "SQL, Project Management, Research                                                         8\n",
       "SQL, Research, Software Engineering                                                       7\n",
       "Python, Project Management, Statistics                                                    6\n",
       "Communication, Research, Project Management                                               6\n",
       "Statistics, Software Engineering, SQL                                                     6\n",
       "                                                                                         ..\n",
       "Communication, Cloud Computing, Python, Data Analysis, SQL                                1\n",
       "Cloud Computing, Data Analysis, Project Management                                        1\n",
       "Software Engineering, Communication, Project Management, SQL, Research                    1\n",
       "Project Management, Data Analysis, Business Analysis, SQL, Research                       1\n",
       "SQL, Research, Cloud Computing, Communication, Software Engineering, Business Analysis    1\n",
       "Name: count, Length: 4162, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count core skill frequencies\n",
    "df['core_skills'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce8ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai_keywords\n",
       "                                                               3377\n",
       "deep learning                                                    72\n",
       "NLP                                                              64\n",
       "machine learning                                                 61\n",
       "reinforcement learning                                           60\n",
       "                                                               ... \n",
       "computer vision, MLOps, machine learning, NLP                     1\n",
       "generative AI, reinforcement learning, LLMs, NLP                  1\n",
       "computer vision, LLMs, machine learning                           1\n",
       "reinforcement learning, MLOps, LLMs                               1\n",
       "NLP, generative AI, reinforcement learning, computer vision       1\n",
       "Name: count, Length: 618, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count AI keyword occurrences\n",
    "df['ai_keywords'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be216158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seniority_level\n",
       "Executive    856\n",
       "Senior       849\n",
       "Lead         844\n",
       "Junior       837\n",
       "Mid          818\n",
       "Intern       796\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank seniority levels by frequency\n",
    "df['seniority_level'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc3f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title\n",
       "ML Engineer           558\n",
       "Operations Manager    525\n",
       "Research Scientist    520\n",
       "AI Researcher         512\n",
       "Systems Engineer      505\n",
       "Software Engineer     492\n",
       "Data Scientist        486\n",
       "Policy Analyst        482\n",
       "Business Analyst      480\n",
       "Product Manager       440\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank job titles by frequency\n",
    "df['job_title'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88f8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Tech             579\n",
       "Manufacturing    573\n",
       "Agriculture      569\n",
       "Retail           567\n",
       "Healthcare       560\n",
       "Finance          549\n",
       "Government       546\n",
       "Education        535\n",
       "Energy           522\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank industries by frequency\n",
    "df['industry'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8c895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_size\n",
       "Small         1031\n",
       "Medium         998\n",
       "Startup        994\n",
       "Large          993\n",
       "Enterprise     984\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank company sizes by frequency\n",
    "df['company_size'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df5e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name\n",
       "Prime Systems           331\n",
       "Future Systems          330\n",
       "Future Solutions        322\n",
       "Future Analytics        319\n",
       "Prime Analytics         317\n",
       "NextGen Solutions       317\n",
       "Future Technologies     315\n",
       "Prime Technologies      312\n",
       "Prime Solutions         310\n",
       "Global Technologies     310\n",
       "NextGen Systems         309\n",
       "NextGen Technologies    308\n",
       "Global Analytics        303\n",
       "Global Solutions        302\n",
       "NextGen Analytics       300\n",
       "Global Systems          295\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank companies by job postings\n",
    "df['company_name'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b4163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "Toronto      390\n",
       "Lagos        378\n",
       "Seoul        377\n",
       "Bangalore    376\n",
       "London       371\n",
       "Berlin       370\n",
       "Nairobi      356\n",
       "Tokyo        353\n",
       "Sao Paulo    352\n",
       "New York     348\n",
       "Paris        346\n",
       "Singapore    341\n",
       "Dubai        330\n",
       "Sydney       312\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank cities by job postings\n",
    "df['city'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8df77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "South America     601\n",
       "North America     585\n",
       "East Asia         564\n",
       "Europe            555\n",
       "Southeast Asia    549\n",
       "Middle East       541\n",
       "South Asia        540\n",
       "Oceania           536\n",
       "Africa            529\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank regions by job postings\n",
    "df['region'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4ad5ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "India          1567\n",
       "None            434\n",
       "IN              230\n",
       "South Korea       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank countries by job postings\n",
    "df['country'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398eadd5",
   "metadata": {},
   "source": [
    "# 3. 데이터 요약하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93e40e",
   "metadata": {},
   "source": [
    "# 4. 데이터 분석하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DA_AI_Jobs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
